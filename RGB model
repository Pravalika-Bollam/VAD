{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8518669,"sourceType":"datasetVersion","datasetId":5086058},{"sourceId":8511331,"sourceType":"datasetVersion","datasetId":5080722}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crime_classes = ['Abuse', 'Arrest', 'Arson', 'Assault', 'RoadAccidents', 'Burglary', 'Explosion', 'Fighting', 'Robbery', 'Shooting', 'Stealing', 'Shoplifting', 'Vandalism']","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:27:39.203541Z","iopub.execute_input":"2024-05-26T04:27:39.203977Z","iopub.status.idle":"2024-05-26T04:27:39.211032Z","shell.execute_reply.started":"2024-05-26T04:27:39.203943Z","shell.execute_reply":"2024-05-26T04:27:39.209344Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\n\nfile_paths = ['/kaggle/input/annotations-formatted/Formatted_annotations/formatted_UCFCrime_Test.txt',\n              '/kaggle/input/annotations-formatted/Formatted_annotations/formatted_UCFCrime_Train.txt',\n              '/kaggle/input/annotations-formatted/Formatted_annotations/formatted_UCFCrime_Val.txt']\n\noutput_file_path = '/kaggle/working/combined_file.txt'\n\nwith open(output_file_path, 'w') as outfile:\n    for file_path in file_paths:\n        with open(file_path, 'r') as infile:\n            for line in infile:\n                outfile.write(line)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:26:07.338047Z","iopub.execute_input":"2024-05-26T04:26:07.338462Z","iopub.status.idle":"2024-05-26T04:26:07.399955Z","shell.execute_reply.started":"2024-05-26T04:26:07.338430Z","shell.execute_reply":"2024-05-26T04:26:07.398751Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def preprocess_text_annotations(annotation_file):\n    video_annotations = {}\n    with open(annotation_file, 'r') as f:\n        lines = f.readlines()\n    for line in lines:\n        parts = line.strip().split(' ')\n        video_id = parts[0]\n        start_time = parts[1]\n        end_time = parts[2]\n        description = ' '.join(parts[3:]).replace('##', '')  \n        if video_id not in video_annotations:\n            video_annotations[video_id] = ''\n        video_annotations[video_id] += \" \" + description\n    return video_annotations","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:26:21.464126Z","iopub.execute_input":"2024-05-26T04:26:21.464621Z","iopub.status.idle":"2024-05-26T04:26:21.473088Z","shell.execute_reply.started":"2024-05-26T04:26:21.464579Z","shell.execute_reply":"2024-05-26T04:26:21.471489Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"annotations_file = \"/kaggle/working/combined_file.txt\"\nannotations = preprocess_text_annotations(annotations_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:26:28.607978Z","iopub.execute_input":"2024-05-26T04:26:28.608610Z","iopub.status.idle":"2024-05-26T04:26:28.703698Z","shell.execute_reply.started":"2024-05-26T04:26:28.608573Z","shell.execute_reply":"2024-05-26T04:26:28.702334Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:26:37.298192Z","iopub.execute_input":"2024-05-26T04:26:37.298576Z","iopub.status.idle":"2024-05-26T04:26:37.357615Z","shell.execute_reply.started":"2024-05-26T04:26:37.298547Z","shell.execute_reply":"2024-05-26T04:26:37.356040Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\n\nbase_dir = \"/kaggle/input/ucf-shanghai-i3d/UCF-Crime/all_rgbs\"\ni3d_features_dict = {}\n\nfor class_name in crime_classes:\n    class_dir = os.path.join(base_dir, class_name)\n    for file_name in os.listdir(class_dir):\n        if file_name.endswith('.npy'):\n            video_id = file_name.split('.')[0]\n            i3d_features_file = os.path.join(class_dir, file_name)\n            i3d_features = np.load(i3d_features_file)\n            i3d_features_dict[video_id] = i3d_features","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:27:56.430202Z","iopub.execute_input":"2024-05-26T04:27:56.431604Z","iopub.status.idle":"2024-05-26T04:28:03.603328Z","shell.execute_reply.started":"2024-05-26T04:27:56.431546Z","shell.execute_reply":"2024-05-26T04:28:03.602184Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:31:16.783570Z","iopub.execute_input":"2024-05-26T04:31:16.784240Z","iopub.status.idle":"2024-05-26T04:31:16.849438Z","shell.execute_reply.started":"2024-05-26T04:31:16.784202Z","shell.execute_reply":"2024-05-26T04:31:16.848325Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1149"},"metadata":{}}]},{"cell_type":"code","source":"for key in list(annotations.keys()):\n    if key.startswith('Normal_Videos'):\n        del annotations[key]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:31:31.858046Z","iopub.execute_input":"2024-05-26T04:31:31.858483Z","iopub.status.idle":"2024-05-26T04:31:31.864943Z","shell.execute_reply.started":"2024-05-26T04:31:31.858449Z","shell.execute_reply":"2024-05-26T04:31:31.863573Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(len(i3d_features_dict), len(annotations))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:32:19.403298Z","iopub.execute_input":"2024-05-26T04:32:19.404333Z","iopub.status.idle":"2024-05-26T04:32:19.411309Z","shell.execute_reply.started":"2024-05-26T04:32:19.404284Z","shell.execute_reply":"2024-05-26T04:32:19.409880Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"950 944\n","output_type":"stream"}]},{"cell_type":"code","source":"keys_only_in_i3d= set(i3d_features_dict.keys()) - set(annotations.keys())\nprint(keys_only_in_i3d)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:32:28.454178Z","iopub.execute_input":"2024-05-26T04:32:28.454709Z","iopub.status.idle":"2024-05-26T04:32:28.461889Z","shell.execute_reply.started":"2024-05-26T04:32:28.454672Z","shell.execute_reply":"2024-05-26T04:32:28.460318Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'Robbery139_x264', 'RoadAccidents063_x264', 'RoadAccidents144_x264', 'Assault045_x264', 'Assault046_x264', 'Vandalism037_x264'}\n","output_type":"stream"}]},{"cell_type":"code","source":"keys_only_in_annotations= set(annotations.keys()) - set(i3d_features_dict.keys()) \nprint(keys_only_in_annotations)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:32:40.377596Z","iopub.execute_input":"2024-05-26T04:32:40.377985Z","iopub.status.idle":"2024-05-26T04:32:40.383815Z","shell.execute_reply.started":"2024-05-26T04:32:40.377957Z","shell.execute_reply":"2024-05-26T04:32:40.382792Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"set()\n","output_type":"stream"}]},{"cell_type":"code","source":"for x in keys_only_in_i3d:\n    del i3d_features_dict[x]","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:33:15.948473Z","iopub.execute_input":"2024-05-26T04:33:15.948906Z","iopub.status.idle":"2024-05-26T04:33:15.954237Z","shell.execute_reply.started":"2024-05-26T04:33:15.948872Z","shell.execute_reply":"2024-05-26T04:33:15.952787Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(len(i3d_features_dict), len(annotations))","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:33:25.313374Z","iopub.execute_input":"2024-05-26T04:33:25.313836Z","iopub.status.idle":"2024-05-26T04:33:25.319940Z","shell.execute_reply.started":"2024-05-26T04:33:25.313801Z","shell.execute_reply":"2024-05-26T04:33:25.319029Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"944 944\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\ni3d_feature = np.load(\"/kaggle/input/ucf-shanghai-i3d/UCF-Crime/all_flows/Fighting/Fighting003_x264.mp4.npy\")\nprint(i3d_feature.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:32:53.328052Z","iopub.execute_input":"2024-05-26T04:32:53.328501Z","iopub.status.idle":"2024-05-26T04:32:53.361510Z","shell.execute_reply.started":"2024-05-26T04:32:53.328466Z","shell.execute_reply":"2024-05-26T04:32:53.360614Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(32, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata = []\nfor video_id, annotations_text in annotations.items():\n    for class_name in crime_classes:\n        if video_id.startswith(class_name):\n            video_class = class_name\n            break\n    data.append({\n        'video_id': video_id,\n        'i3d_features': i3d_features_dict[video_id],\n        'annotations': annotations_text,\n        'video_class': video_class\n    })\n\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:33:34.612920Z","iopub.execute_input":"2024-05-26T04:33:34.613296Z","iopub.status.idle":"2024-05-26T04:33:34.988891Z","shell.execute_reply.started":"2024-05-26T04:33:34.613268Z","shell.execute_reply":"2024-05-26T04:33:34.987915Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:33:41.888313Z","iopub.execute_input":"2024-05-26T04:33:41.889943Z","iopub.status.idle":"2024-05-26T04:33:42.067971Z","shell.execute_reply.started":"2024-05-26T04:33:41.889891Z","shell.execute_reply":"2024-05-26T04:33:42.066767Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"        video_id                                       i3d_features  \\\n0  Abuse037_x264  [[0.02243881, 0.02822475, 0.031023769, 0.02028...   \n1  Abuse038_x264  [[0.026130054, 0.021396607, 0.02964775, 0.0310...   \n2  Abuse039_x264  [[0.016784675, 0.06679627, 0.023015551, 0.0249...   \n3  Abuse040_x264  [[0.029799832, 0.025534721, 0.0363178, 0.04318...   \n4  Abuse041_x264  [[0.008967045, 0.022280507, 0.021141257, 0.032...   \n\n                                         annotations video_class  \n0   A white car with double flashes slowly appear...       Abuse  \n1    Several adults were talking on the side of t...       Abuse  \n2   A yellow-haired woman in black clothes walked...       Abuse  \n3   A woman in a blue top walked into the room ne...       Abuse  \n4   A woman wearing pink clothes is holding a chi...       Abuse  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_id</th>\n      <th>i3d_features</th>\n      <th>annotations</th>\n      <th>video_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abuse037_x264</td>\n      <td>[[0.02243881, 0.02822475, 0.031023769, 0.02028...</td>\n      <td>A white car with double flashes slowly appear...</td>\n      <td>Abuse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abuse038_x264</td>\n      <td>[[0.026130054, 0.021396607, 0.02964775, 0.0310...</td>\n      <td>Several adults were talking on the side of t...</td>\n      <td>Abuse</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Abuse039_x264</td>\n      <td>[[0.016784675, 0.06679627, 0.023015551, 0.0249...</td>\n      <td>A yellow-haired woman in black clothes walked...</td>\n      <td>Abuse</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Abuse040_x264</td>\n      <td>[[0.029799832, 0.025534721, 0.0363178, 0.04318...</td>\n      <td>A woman in a blue top walked into the room ne...</td>\n      <td>Abuse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Abuse041_x264</td>\n      <td>[[0.008967045, 0.022280507, 0.021141257, 0.032...</td>\n      <td>A woman wearing pink clothes is holding a chi...</td>\n      <td>Abuse</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer\nimport pandas as pd\nimport re\n\ntokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef tokenize_annotation(annotation):\n    processed_annotation = preprocess_text(annotation)\n    return tokenizer.encode(processed_annotation)\n\ndf['tokenized_annotations'] = df['annotations'].apply(tokenize_annotation)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:34:06.497989Z","iopub.execute_input":"2024-05-26T04:34:06.498487Z","iopub.status.idle":"2024-05-26T04:34:17.143159Z","shell.execute_reply.started":"2024-05-26T04:34:06.498430Z","shell.execute_reply":"2024-05-26T04:34:17.142033Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b4cb8a83d0498fa32dfc8dc7959bb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5884746f9d984504b8741f3432bcf46e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a19e786e4ea40659c9d096a241bfe9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ccd74d53f1448f912940368b4fe378"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"annotations_string = df.at[3, 'annotations']  \nwords = annotations_string.split()\nnum_words = len(words)\nprint(\"Number of words:\", num_words)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:34:43.478429Z","iopub.execute_input":"2024-05-26T04:34:43.478837Z","iopub.status.idle":"2024-05-26T04:34:43.486061Z","shell.execute_reply.started":"2024-05-26T04:34:43.478807Z","shell.execute_reply":"2024-05-26T04:34:43.484619Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Number of words: 175\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nmax_len = df['tokenized_annotations'].apply(len).max()\ndf['tokenized_annotations'] = pad_sequences(df['tokenized_annotations'], maxlen=max_len, padding='post').tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:35:08.293068Z","iopub.execute_input":"2024-05-26T04:35:08.293455Z","iopub.status.idle":"2024-05-26T04:35:21.991197Z","shell.execute_reply.started":"2024-05-26T04:35:08.293427Z","shell.execute_reply":"2024-05-26T04:35:21.990309Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"2024-05-26 04:35:10.688275: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-26 04:35:10.688448: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-26 04:35:10.854095: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"max_len","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:35:21.992885Z","iopub.execute_input":"2024-05-26T04:35:21.993533Z","iopub.status.idle":"2024-05-26T04:35:22.002207Z","shell.execute_reply.started":"2024-05-26T04:35:21.993494Z","shell.execute_reply":"2024-05-26T04:35:22.000968Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"2553"},"metadata":{}}]},{"cell_type":"code","source":"annotation_lengths = df['tokenized_annotations'].apply(len)\nunique_lengths = annotation_lengths.unique()\nprint(\"Unique Annotation Lengths:\", unique_lengths)\n\nprint(\"Minimum Length:\", annotation_lengths.min())\nprint(\"Maximum Length:\", annotation_lengths.max())\nprint(\"Mean Length:\", annotation_lengths.mean())","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:35:25.042991Z","iopub.execute_input":"2024-05-26T04:35:25.043408Z","iopub.status.idle":"2024-05-26T04:35:25.057312Z","shell.execute_reply.started":"2024-05-26T04:35:25.043367Z","shell.execute_reply":"2024-05-26T04:35:25.055792Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Unique Annotation Lengths: [2553]\nMinimum Length: 2553\nMaximum Length: 2553\nMean Length: 2553.0\n","output_type":"stream"}]},{"cell_type":"code","source":"unique_shapes = set()\nfor features in df['i3d_features']:\n    unique_shapes.add(features.shape)\n\nprint(\"Unique shapes of i3d_features:\")\nfor shape in unique_shapes:\n    print(shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:35:35.523081Z","iopub.execute_input":"2024-05-26T04:35:35.524690Z","iopub.status.idle":"2024-05-26T04:35:35.532784Z","shell.execute_reply.started":"2024-05-26T04:35:35.524625Z","shell.execute_reply":"2024-05-26T04:35:35.531607Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Unique shapes of i3d_features:\n(32, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = len(tokenizer.vocab)\nprint(vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:35:45.768155Z","iopub.execute_input":"2024-05-26T04:35:45.768607Z","iopub.status.idle":"2024-05-26T04:35:45.775628Z","shell.execute_reply.started":"2024-05-26T04:35:45.768575Z","shell.execute_reply":"2024-05-26T04:35:45.774746Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"30522\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Concatenate, LSTM, Embedding, Conv1D, MaxPooling1D, Bidirectional, Reshape\nfrom tensorflow.keras.utils import to_categorical\n\nX_i3d = np.array(df['i3d_features'].tolist())  # Shape: (num_samples, 32, 1024)\nX_tokenized = np.array(df['tokenized_annotations'].tolist())  # Shape: (num_samples, 2553)\n\ny = df['video_class']\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\nnum_classes = len(label_encoder.classes_)\n\nX_train_i3d, X_test_i3d, X_train_tokenized, X_test_tokenized, y_train, y_test = train_test_split(X_i3d, X_tokenized, y_encoded, test_size=0.2, random_state=42)\n\n\ninput_i3d = Input(shape=(32, 1024))  # Shape of i3d features\ninput_tokenized = Input(shape=(2553,))  # Length of tokenized annotations\n\n# CNN layer for i3d features\ncnn_i3d = Conv1D(64, 3, activation='relu')(input_i3d)\nmaxpool_i3d = MaxPooling1D(2)(cnn_i3d)\nflatten_i3d = Reshape((-1,))(maxpool_i3d)\ndense_i3d = Dense(512, activation='relu')(flatten_i3d)\n\n# BiLSTM layer for tokenized annotations\nembedding_layer = Embedding(input_dim=vocab_size, output_dim=100, input_length=2553)(input_tokenized)\nlstm_layer = Bidirectional(LSTM(128))(embedding_layer)\n\n# Concatenate the outputs of CNN and BiLSTM layers\nconcatenated = Concatenate()([dense_i3d, lstm_layer])\n\n# Add additional layers for classification\noutput = Dense(num_classes, activation='softmax')(concatenated)\n\n# Create model\nmodel = Model(inputs=[input_i3d, input_tokenized], outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhybrid_history = model.fit([X_train_i3d, X_train_tokenized], y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T04:36:27.883402Z","iopub.execute_input":"2024-05-26T04:36:27.883859Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.1474 - loss: 2.5046 - val_accuracy: 0.3179 - val_loss: 2.3351\nEpoch 2/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - accuracy: 0.2477 - loss: 2.3141 - val_accuracy: 0.3642 - val_loss: 1.9673\nEpoch 3/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 5s/step - accuracy: 0.3370 - loss: 2.0057 - val_accuracy: 0.4570 - val_loss: 1.8302\nEpoch 4/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.4368 - loss: 1.8323 - val_accuracy: 0.4636 - val_loss: 1.7203\nEpoch 5/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 5s/step - accuracy: 0.4557 - loss: 1.6671 - val_accuracy: 0.4503 - val_loss: 1.6842\nEpoch 6/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - accuracy: 0.4613 - loss: 1.5392 - val_accuracy: 0.4702 - val_loss: 1.5723\nEpoch 7/10\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5s/step - accuracy: 0.4798 - loss: 1.4604 - val_accuracy: 0.5166 - val_loss: 1.5631\nEpoch 8/10\n\u001b[1m16/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m13s\u001b[0m 4s/step - accuracy: 0.6288 - loss: 1.1688","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate([X_test_i3d, X_test_tokenized], y_test)\nprint(\"Test Loss:\", loss)\nprint(\"Test Accuracy:\", accuracy)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(hybrid_history.history['accuracy'], label='Training Accuracy')\nplt.plot(hybrid_history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/hybrid_accuracy.png\")\n\n# Plot training and validation loss\nplt.plot(hybrid_history.history['loss'], label='Training Loss')\nplt.plot(hybrid_history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/hybrid_loss.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nimport numpy as np\n\n\ny_prob = model.predict([X_test_i3d, X_test_tokenized])\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin = lb.transform(y_test)\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()c\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nplt.figure(figsize=(8, 6))\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve (class %d) (AUC = %0.2f)' % (i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for each class')\n\nmacro_auc = np.mean(list(roc_auc.values()))\n\n\ny_prob_flat = y_prob.ravel()\ny_test_bin_flat = y_test_bin.ravel()\nmicro_auc = roc_auc_score(y_test_bin_flat, y_prob_flat, average='micro')\n\n\nplt.text(0.6, 0.1, f'Macro-average AUC: {macro_auc:.3f}\\nMicro-average AUC: {micro_auc:.3f}', fontsize=12, ha='center')\n\nplt.legend(loc=\"lower right\")\nplt.show()\nplt.savefig(\"/kaggle/working/hybrid_model_multiclass_ROC.png\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, average_precision_score\n\nprecision = dict()\nrecall = dict()\naverage_precision = dict()\nfor i in range(num_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:, i], y_prob[:, i])\n    average_precision[i] = average_precision_score(y_test_bin[:, i], y_prob[:, i])\n\nplt.figure(figsize=(8, 6))\nfor i in range(num_classes):\n    plt.plot(recall[i], precision[i], label='Precision-recall curve (class %d) (AP = %0.2f)' % (i, average_precision[i]))\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve for each class')\n\nmacro_average_precision = np.mean(list(average_precision.values()))\n\ny_prob_flat = y_prob.ravel()\ny_test_bin_flat = y_test_bin.ravel()\nmicro_average_precision = average_precision_score(y_test_bin_flat, y_prob_flat, average='micro')\n\nplt.text(0.6, 0.1, f'Macro-average Precision: {macro_average_precision:.3f}\\nMicro-average Precision: {micro_average_precision:.3f}', fontsize=12, ha='center')\n\nplt.legend(loc=\"lower left\")\nplt.show()\nplt.savefig(\"/kaggle/working/hybrid_model_multiclass_Precision_Recall.png\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_i3d = Input(shape=(32, 1024)) \ncnn_i3d = Conv1D(64, 3, activation='relu')(input_i3d)\nmaxpool_i3d = MaxPooling1D(2)(cnn_i3d)\nflatten_i3d = Reshape((-1,))(maxpool_i3d)\ndense_i3d = Dense(512, activation='relu')(flatten_i3d)\n\n# Additional layers for classification\noutput_i3d = Dense(num_classes, activation='softmax')(dense_i3d)\nmodel_i3d = Model(inputs=input_i3d, outputs=output_i3d)\nmodel_i3d.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\ni3d_history = model_i3d.fit(X_train_i3d, y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_i3d, accuracy_i3d = model_i3d.evaluate(X_test_i3d, y_test)\nprint(\"Test Loss:\", loss_i3d)\nprint(\"Test Accuracy:\", accuracy_i3d)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and validation accuracy\nplt.plot(i3d_history.history['accuracy'], label='Training Accuracy')\nplt.plot(i3d_history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy (i3d only)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/i3d_model_accuracy.png\")\n\n# Plot training and validation loss\nplt.plot(i3d_history.history['loss'], label='Training Loss')\nplt.plot(i3d_history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss (i3d only)')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/i3d_model_history.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = model_i3d.predict(X_test_i3d)\n\n# Convert labels to binary format\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin = lb.transform(y_test)\n\n# Calculate ROC curve and AUC for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot ROC curve for each class\nplt.figure(figsize=(8, 6))\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve (class %d) (AUC = %0.2f)' % (i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for each class')\n\n\n# Calculate macro-average AUC\nmacro_auc = np.mean(list(roc_auc.values()))\n\n# Calculate micro-average AUC\ny_prob_flat = y_prob.ravel()\ny_test_bin_flat = y_test_bin.ravel()\nmicro_auc = roc_auc_score(y_test_bin_flat, y_prob_flat, average='micro')\n\n\nplt.text(0.6, 0.1, f'Macro-average AUC: {macro_auc:.3f}\\nMicro-average AUC: {micro_auc:.3f}', fontsize=12, ha='center')\nplt.legend(loc=\"lower right\")\nplt.savefig(\"/kaggle/working/i3d_model_multiclass_ROC.png\")\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_tokenized = Input(shape=(2553,)) \nembedding_layer = Embedding(input_dim=vocab_size, output_dim=100, input_length=2553)(input_tokenized)\nlstm_layer = LSTM(128)(embedding_layer)\noutput = Dense(num_classes, activation='softmax')(lstm_layer)\nmodel_lstm = Model(inputs=input_tokenized, outputs=output)\nmodel_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory_lstm = model_lstm.fit(X_train_tokenized, y_train, epochs=10, batch_size=32, validation_split=0.2)\n\nlstm_loss, lstm_accuracy = model_lstm.evaluate(X_test_tokenized, y_test)\nprint(\"Test Loss:\", lstm_loss)\nprint(\"Test Accuracy:\", lstm_accuracy)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and validation accuracy\nplt.plot(history_lstm.history['accuracy'], label='Training Accuracy')\nplt.plot(history_lstm.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy (i3d only)')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/lstm_model_accuracy.png\")\n\n# Plot training and validation loss\nplt.plot(history_lstm.history['loss'], label='Training Loss')\nplt.plot(history_lstm.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss (i3d only)')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\nplt.savefig(\"/kaggle/working/lstm_model_loss.png\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = model_lstm.predict(X_test_tokenized)\n\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin = lb.transform(y_test)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(8, 6))\nfor i in range(num_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve (class %d) (AUC = %0.2f)' % (i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve for each class')\n\nmacro_auc = np.mean(list(roc_auc.values()))\n\ny_prob_flat = y_prob.ravel()\ny_test_bin_flat = y_test_bin.ravel()\nmicro_auc = roc_auc_score(y_test_bin_flat, y_prob_flat, average='micro')\n\nplt.text(0.6, 0.1, f'Macro-average AUC: {macro_auc:.3f}\\nMicro-average AUC: {micro_auc:.3f}', fontsize=12, ha='center')\nplt.legend(loc=\"lower right\")\nplt.savefig(\"/kaggle/working/lstm_model_multiclass_ROC.png\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob = model.predict([X_test_i3d, X_test_tokenized])\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin = lb.transform(y_test)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(num_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Calculate mean false positive rates and true positive rates\nall_fpr_tokenized_lstm = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\nmean_tpr_tokenized_lstm = np.zeros_like(all_fpr_tokenized_lstm)\nfor i in range(num_classes):\n    mean_tpr_tokenized_lstm += np.interp(all_fpr_tokenized_lstm, fpr[i], tpr[i])\n\nmean_tpr_tokenized_lstm /= num_classes\n\n# Calculate overall ROC AUC\noverall_auc_tokenized_lstm = auc(all_fpr_tokenized_lstm, mean_tpr_tokenized_lstm)\n\n# Plot overall ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(all_fpr_tokenized_lstm, mean_tpr_tokenized_lstm, label='Overall ROC curve (AUC = %0.2f)' % overall_auc_tokenized_lstm, color='b')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve (Overall) for Tokenized LSTM')\nplt.legend(loc=\"lower right\")\nplt.savefig(\"/kaggle/working/hybrid_all_ROC_CURVE.png\")\nplt.show()\n\n# Print the overall ROC AUC\nprint(\"Overall ROC AUC (Tokenized LSTM):\", overall_auc_tokenized_lstm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob_i3d = model_i3d.predict(X_test_i3d)\n\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin_i3d = lb.transform(y_test)\n\nfpr_i3d = dict()\ntpr_i3d = dict()\nroc_auc_i3d = dict()\nfor i in range(num_classes):\n    fpr_i3d[i], tpr_i3d[i], _ = roc_curve(y_test_bin_i3d[:, i], y_prob_i3d[:, i])\n    roc_auc_i3d[i] = auc(fpr_i3d[i], tpr_i3d[i])\n\n# Calculate mean false positive rates and true positive rates\nall_fpr_i3d = np.unique(np.concatenate([fpr_i3d[i] for i in range(num_classes)]))\nmean_tpr_i3d = np.zeros_like(all_fpr_i3d)\nfor i in range(num_classes):\n    mean_tpr_i3d += np.interp(all_fpr_i3d, fpr_i3d[i], tpr_i3d[i])\nmean_tpr_i3d /= num_classes\n\n# Calculate overall ROC AUC\noverall_auc_i3d = auc(all_fpr_i3d, mean_tpr_i3d)\n\n# Plot overall ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(all_fpr_i3d, mean_tpr_i3d, label='Overall ROC curve (AUC = %0.2f)' % overall_auc_i3d, color='b')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve (Overall) for i3d')\nplt.legend(loc=\"lower right\")\nplt.savefig(\"/kaggle/working/i3d_all_ROC_CURVE.png\")\nplt.show()\n\nprint(\"Overall ROC AUC (i3d):\", overall_auc_i3d)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_prob_lstm = model_lstm.predict(X_test_tokenized)\n\nlb = LabelBinarizer()\nlb.fit(y_test)\ny_test_bin_lstm = lb.transform(y_test)\n\nfpr_lstm = dict()\ntpr_lstm = dict()\nroc_auc_lstm = dict()\nfor i in range(num_classes):\n    fpr_lstm[i], tpr_lstm[i], _ = roc_curve(y_test_bin_lstm[:, i], y_prob_lstm[:, i])\n    roc_auc_lstm[i] = auc(fpr_lstm[i], tpr_lstm[i])\n\n# Calculate mean false positive rates and true positive rates\nall_fpr_lstm = np.unique(np.concatenate([fpr_lstm[i] for i in range(num_classes)]))\nmean_tpr_lstm = np.zeros_like(all_fpr_lstm)\nfor i in range(num_classes):\n    mean_tpr_lstm += np.interp(all_fpr_lstm, fpr_lstm[i], tpr_lstm[i])\nmean_tpr_lstm /= num_classes\n\n# Calculate overall ROC AUC\noverall_auc_lstm = auc(all_fpr_lstm, mean_tpr_lstm)\n\n# Plot overall ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(all_fpr_lstm, mean_tpr_lstm, label='Overall ROC curve (AUC = %0.2f)' % overall_auc_lstm, color='b')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve (Overall) for LSTM')\nplt.legend(loc=\"lower right\")\nplt.savefig(\"/kaggle/working/lstm_all_ROC_CURVE.png\")\nplt.show()\n\n# Print the overall ROC AUC\nprint(\"Overall ROC AUC (LSTM):\", overall_auc_lstm)","metadata":{},"execution_count":null,"outputs":[]}]}